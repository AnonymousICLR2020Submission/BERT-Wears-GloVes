# ICLR 2020 Submission - BERT Wears GloVes: Distilling Static Embeddings from Pretrained Contextual Representations 
Distilling static word embeddings from pretrained contextual representations (e.g. BERT)
